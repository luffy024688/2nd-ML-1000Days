{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解如何使用 Sklearn 中的 hyper-parameter search 找出最佳的超參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier                           # GBM\n",
    "from sklearn.ensemble import RandomForestClassifier# 隨機森林\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# 1. get data\n",
    "digits = datasets.load_digits()\n",
    "#digits = datasets.load_breast_cancer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. split data\n",
    "x_train,x_test,y_train,y_test = train_test_split(digits.data,digits.target,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 建立Model\n",
    "#clf = GradientBoostingClassifier ()\n",
    "clf = GradientBoostingClassifier (loss = 'deviance',learning_rate=0.1, n_estimators=100)\n",
    "\n",
    "#clf = RandomForestClassifier()\n",
    "# 3.2 訓練Model\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 預測\n",
    "y_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711111111111111"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 評分\n",
    "metrics.accuracy_score(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   27.6s finished\n"
     ]
    }
   ],
   "source": [
    "# 6.1 \n",
    "n_estimators = [50, 100, 150]\n",
    "learning_rate = [0.1, 0.2,0.3]\n",
    "#max_depth = [1, 3, 5]\n",
    "\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators, learning_rate = learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# 6.2.1\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring=\"accuracy\", n_jobs=-1, verbose=1)   #Model\n",
    "# 6.2.2\n",
    "grid_result = grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'n_estimators': 100}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier (loss = 'deviance',learning_rate=0.2, n_estimators=50)\n",
    "#clf = GradientBoostingClassifier(learning_rate=grid_result.best_params_['max_depth'],n_estimators=grid_result.best_params_['n_estimators'])\n",
    "clf.fit(x_train,y_train)\n",
    "y_predict = clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q：分數變低？\n",
    "\n",
    "\n",
    "因為 GridSearch 是針對特定資料&模型做參數優化，你這邊優化的目標只有 training data。所以用在 testing data反而變差，那 training & testing data 的權衡通常會搭配 cross validation 的方式。官方有一個範例是 GridSearch + Cross-Validation： https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "\n",
    "Q：每次不一樣？\n",
    "Notes\n",
    "\n",
    "The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed.\n",
    "\n",
    "意思就是要使用 random_state 才會有固定的結果。另外 Regressor 那邊感謝你的提醒，程式碼已經有修正囉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
